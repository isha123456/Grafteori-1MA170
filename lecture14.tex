\documentclass[nobib]{tufte-handout}

\title{Lecture 14: The probabilistic method and the Erd\H{o}s-Rényi random graph $\cdot$ 1MA020}

\author[Vilhelm Agdur]{Vilhelm Agdur\thanks{\href{mailto:vilhelm.agdur@math.uu.se}{\nolinkurl{vilhelm.agdur@math.uu.se}}}}

\date{28 November 2023}


%\geometry{showframe} % display margins for debugging page layout

\usepackage{graphicx} % allow embedded images
  \setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
  \graphicspath{{graphics/}} % set of paths to search for images
\usepackage{amsmath}  % extended mathematics
\usepackage{booktabs} % book-quality tables
\usepackage{units}    % non-stacked fractions and better unit spacing
\usepackage{multicol} % multiple column layout facilities
\usepackage{lipsum}   % filler text
\usepackage{fancyvrb} % extended verbatim environments
  \fvset{fontsize=\normalsize}% default font size for fancy-verbatim environments

\usepackage{color,soul} % Highlights for text

% Standardize command font styles and environments
\newcommand{\doccmd}[1]{\texttt{\textbackslash#1}}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newcommand{\docenv}[1]{\textsf{#1}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}}% document class option name
\newenvironment{docspec}{\begin{quote}\noindent}{\end{quote}}% command specification environment

\include{mathcommands.extratex}

\begin{document}

\maketitle% this prints the handout title, author, and date

\begin{abstract}
\noindent
We introduce a new tool to the course, the probabilistic method, and use it to prove some new results. We also introduce the Erd\H{o}s-Rényi random graph, which is interesting in its own right as well as being a tool in the probabilistic method.
\end{abstract}

\section{The minimum bisection problem}

Suppose we are given a graph $G$, which is too large to fit on a single computer -- so we wish to distribute the computation we want to do on the graph between two machines. We imagine the computation we want to do is in some sense possible to do ``locally'' -- so if the graph had two equally sized connected components, the two computers wouldn't have to talk to each other at all.

Of course, most graphs do not split up that nicely, but we can still try to divide it into two equally sized parts that have as few edges between them as possible. How well can we do this?

\begin{proposition}
  For any graph $G = (V,E)$ on $n \in 2\N$ vertices with maximum degree $\Delta < \frac{n}{2}$, there exists a partition $A \coprod B$ of $V$, such that $\abs{A} = \abs{B} = \frac{n}{2}$, and
  $$e(A,B) \leq \frac{\abs{E}}{2},$$
  where $e(A,B)$ is the number of edges between $A$ and $B$.

  \begin{proof}
    Let $G^c$ be the complement graph of $G$ -- that is, $G^c$ has the same vertices as $G$, and there is an edge $x \sim y$ in $G^c$ if and only if $x \sim y$ is not an edge of $G$.

    Since we assumed $\Delta < \frac{n}{2}$, it is clear that the \emph{minimum} degree of $G^c$ is at least $\frac{n}{2}$, and so by Dirac's theorem\sidenote[][]{Which we proved earlier in the course.} there exists a Hamilton cycle in $G^c$. Picking every second edge of this Hamilton cycle, we get a perfect matching $M$ on $G^c$.

    Now, we apply the probabilistic method, picking a random partition $A \coprod B$ of $V$: For each edge of $M$, we randomly place one of its endpoints in $A$ and one in $B$, independently between different edges. We can then compute that
    \begin{align*}
      \E{\abs{e(A,B)}} &= \E{\sum_{x \sim y \in E} \ind{x \sim y \in E(A,B)}}\\
      &= \sum_{x \sim y \in E} \Prob{x\text{ and }y\text{ are in different sets}}.
    \end{align*}

    Now, whenever $x$ and $y$ are not connected by an edge in $M$, their assignment to $A$ or $B$ is independent, and so the probability that they are in different sets is precisely $\frac{1}{2}$. However, we picked our matching $M$ so that it is a perfect matching on $G^c$ -- in particular this means that $M \cap E = \emptyset$, and so all of the probabilities that we are summing must in fact be $\frac{1}{2}$ by our previous argument.

    So the sum is just a sum of $\abs{E}$ many $\frac{1}{2}$'s, and so what we have seen is that $\E{\abs{e(A,B)}} = \frac{\abs{E}}{2}$. Now, we know that the expectation is never greater than every specific outcome, so there must exist some choice of $A$ and $B$ with no more than $\frac{\abs{E}}{2}$ edges between them, and we have shown the proposition.
  \end{proof}
\end{proposition}

\section{Girth and chromatic number}

Already when we first introduced the chromatic number, we mentioned the obvious fact that a large clique forces a graph to have high chromatic number. One might be led by this to believe that being very sparse, without any cliques, would mean you have low chromatic number. This unfortunately turns out to be not at all true, in a pretty strong sense.

\begin{definition}
  The \emph{girth} of a graph $G$ is the length of the shortest cycle in the graph.
\end{definition}

So the notion of girth generalizes the notion of being triangle-free, which is just having girth greater than three. Of course any triangle-free graph also contains no larger cliques, so this is indeed a strong notion of having no cliques.

\begin{theorem}[Erd\H{o}s, 1959]
  For all positive integers $k$ there exists a graph $G$ of girth and chromatic number at least $k$.
\end{theorem}

The proof of this uses the probabilistic method, and proceeds by considering a random graph from a suitably chosen distribution, and showing that the probability that it has girth and chromatic number at least $k$ is greater than $0$. We postpone the proof of this until a later lecture, when we will have developed our probabilistic toolbox a bit more.


\section{Exercises}


%\bibliography{references}
%\bibliographystyle{plainnat}

\end{document}
