\documentclass[nobib]{tufte-handout}

\title{Lecture 14: The probabilistic method and the Erd\H{o}s-Rényi random graph $\cdot$ 1MA020}

\author[Vilhelm Agdur]{Vilhelm Agdur\thanks{\href{mailto:vilhelm.agdur@math.uu.se}{\nolinkurl{vilhelm.agdur@math.uu.se}}}}

\date{28 November 2023}


%\geometry{showframe} % display margins for debugging page layout

\usepackage{graphicx} % allow embedded images
  \setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
  \graphicspath{{graphics/}} % set of paths to search for images
\usepackage{amsmath}  % extended mathematics
\usepackage{booktabs} % book-quality tables
\usepackage{units}    % non-stacked fractions and better unit spacing
\usepackage{multicol} % multiple column layout facilities
\usepackage{lipsum}   % filler text
\usepackage{fancyvrb} % extended verbatim environments
  \fvset{fontsize=\normalsize}% default font size for fancy-verbatim environments

\usepackage{color,soul} % Highlights for text

% Standardize command font styles and environments
\newcommand{\doccmd}[1]{\texttt{\textbackslash#1}}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newcommand{\docenv}[1]{\textsf{#1}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}}% document class option name
\newenvironment{docspec}{\begin{quote}\noindent}{\end{quote}}% command specification environment

\include{mathcommands.extratex}

\begin{document}

\maketitle% this prints the handout title, author, and date

\begin{abstract}
\noindent
We introduce a new tool to the course, the probabilistic method, and use it to prove some new results. We also introduce the Erd\H{o}s-Rényi random graph, which is interesting in its own right as well as being a tool in the probabilistic method.
\end{abstract}

\section{The minimum bisection problem}

Suppose we are given a graph $G$, which is too large to fit on a single computer -- so we wish to distribute the computation we want to do on the graph between two machines. We imagine the computation we want to do is in some sense possible to do ``locally'' -- so if the graph had two equally sized connected components, the two computers wouldn't have to talk to each other at all.

Of course, most graphs do not split up that nicely, but we can still try to divide it into two equally sized parts that have as few edges between them as possible. How well can we do this?

\begin{proposition}
  For any graph $G = (V,E)$ on $n \in 2\N$ vertices with maximum degree $\Delta < \frac{n}{2}$, there exists a partition $A \coprod B$ of $V$, such that $\abs{A} = \abs{B} = \frac{n}{2}$, and
  $$e(A,B) \leq \frac{\abs{E}}{2},$$
  where $e(A,B)$ is the number of edges between $A$ and $B$.

  \begin{proof}
    Let $G^c$ be the complement graph of $G$ -- that is, $G^c$ has the same vertices as $G$, and there is an edge $x \sim y$ in $G^c$ if and only if $x \sim y$ is not an edge of $G$.

    Since we assumed $\Delta < \frac{n}{2}$, it is clear that the \emph{minimum} degree of $G^c$ is at least $\frac{n}{2}$, and so by Dirac's theorem\sidenote[][]{Which we proved earlier in the course.} there exists a Hamilton cycle in $G^c$. Picking every second edge of this Hamilton cycle, we get a perfect matching $M$ on $G^c$.

    Now, we apply the probabilistic method, picking a random partition $A \coprod B$ of $V$: For each edge of $M$, we randomly place one of its endpoints in $A$ and one in $B$, independently between different edges. We can then compute that
    \begin{align*}
      \E{\abs{e(A,B)}} &= \E{\sum_{x \sim y \in E} \ind{x \sim y \in E(A,B)}}\\
      &= \sum_{x \sim y \in E} \Prob{x\text{ and }y\text{ are in different sets}}.
    \end{align*}

    Now, whenever $x$ and $y$ are not connected by an edge in $M$, their assignment to $A$ or $B$ is independent, and so the probability that they are in different sets is precisely $\frac{1}{2}$. However, we picked our matching $M$ so that it is a perfect matching on $G^c$ -- in particular this means that $M \cap E = \emptyset$, and so all of the probabilities that we are summing must in fact be $\frac{1}{2}$ by our previous argument.

    So the sum is just a sum of $\abs{E}$ many $\frac{1}{2}$'s, and so what we have seen is that $\E{\abs{e(A,B)}} = \frac{\abs{E}}{2}$. Now, we know that the expectation is never greater than every specific outcome, so there must exist some choice of $A$ and $B$ with no more than $\frac{\abs{E}}{2}$ edges between them, and we have shown the proposition.
  \end{proof}
\end{proposition}

\section{The Erd\H{o}s-Rényi graph}

As we saw in the previous exercise session, the simplest and most common random graph model is the Erd\H{o}s-Rényi graph, where all edges appear independently with the same probability. Let us restate the definition here, for completeness.

\begin{definition}
  For any integer $n \in \N$ and any probability $p \in [0,1]$, the \emph{Erd\H{o}s-Rényi graph} $G(n,p)$ is a random graph on $n$ vertices,\sidenote[][]{We will normally assume its vertex set is $[n]$, unless otherwise stated.} where each of the $\binom{n}{2}$ potential edges is present independently at random with probability $p$.
\end{definition}

\begin{proposition}
  Let $\Hat G = (V,E)$ be a labelled graph on $n$ vertices, and $G = G(n,p)$ be an Erd\H{o}s-Rényi graph on the same number of vertices. The probability that $G = \Hat G$ is precisely
  $$\Prob{G = \Hat G} = p^{\abs{E}}(1-p)^{\binom{n}{2} - \abs{E}},$$
  and so in particular if $p = \frac{1}{2}$, the Erd\H{o}s-Rényi graph is in fact a uniformly random graph.
\end{proposition}

We proved two things about the Erd\H{o}s-Rényi graph during the exercises, but let us restate those results and their proofs here.

\begin{lemma}
  If $G = G(n,p)$ is an Erd\H{o}s-Rényi graph, the probability that it has an independent set of size at least $k$ is bounded by
  $$\Prob{\alpha(G) \geq k} \leq \binom{n}{k}(1-p)^{\binom{k}{2}}.$$

  \begin{proof}
    There are a total of $\binom{n}{k}$ subsets of $[n]$ of size $k$, so for each such set $X \in \binom{[n]}{k}$, let $A_X$ be the event that $X$ is an independent set in $G$.

    Clearly, $A_X$ happens whenever none of the $\binom{k}{2}$ possible edges inside $X$ are present, which happens with probability $(1-p)^{\binom{k}{2}}$. So we can calculate, using a union bound, that
    \begin{align*}
      \Prob{\alpha(G) \geq k} &= \Prob{\bigcup_{X \in \binom{[n]}{k}} A_X}\\
      &\leq \sum_{X \in \binom{[n]}{k}} \Prob{A_X}\\
      &= \sum_{X \in \binom{[n]}{k}} (1-p)^{\binom{k}{2}} = \binom{n}{k}(1-p)^{\binom{k}{2}}
    \end{align*}
    where we used in the last equality that we had $\binom{n}{k}$ summands, giving the lemma.
  \end{proof}
\end{lemma}

\begin{proposition}
  For any $p \in (0,1)$, if $G_n = G(n,p)$ is an Erd\H{o}s-Rényi graph for each $n$, it holds that
  $$\Prob{\diam(G_n) = 2} \to 1\quad\text{as}\quad n \to \infty.$$
\end{proposition}

It is somewhat cumbersome to explicitly write out the sequence of random graphs and the limit every time we want to say something about an asymptotic property of the Erd\H{o}s-Rényi graph, so we will generally use the following way of phrasing such results instead:

\begin{proposition}
  For each fixed $p \in (0,1)$, it holds that $\diam(G(n,p)) = 2$ with high probability.\sidenote[][-1cm]{We also synonymously say that a property holds ``asymptotically almost surely'' -- these two phrases are then abbreviated to ``w.h.p.'' or ``a.a.s.'' when convenient. In both cases, what we mean is that the property holds with probability tending to one as we increase the number of vertices of the graph.}

  \begin{proof}
    The only graphs with diameter one are the complete graphs, and it is easy to see\sidenote[][]{
      \begin{xca}
        See this.
      \end{xca}
    } that the Erd\H{o}s-Rényi graph is not complete w.h.p. for any $p < 1$. So all we need to do is to show that $\diam G(n,p) \leq 2$ w.h.p.

    So, for any pair of two distinct vertices $i$ and $j$, let $B_{ij}$ be the event that there is no edge between $i$ and $j$ and they additionally have no common neighbour. We call such a pair of vertices a \emph{bad} pair -- it is clear that a graph has diameter at most two precisely when it has no bad pairs.
    
    Now we can compute, using the fact that edges appear independently, that
    \begin{align*}
      \Prob{B_{ij}} &= \Prob{\left(i \sim j \not\in E\right) \wedge \left(\bigwedge_{k \in [n]\setminus \{i,j\}} (i \sim k \not\in E)\vee (k \sim j \not \in E)\right)}\\
      &= (1-p)\prod_{k \in [n] \setminus \{i,j\}} \Prob{(i \sim k \not\in E)\vee (k \sim j \not \in E)}\\
      &= (1-p)\prod_{k \in [n] \setminus \{i,j\}} (1 - p^2) = (1-p)(1 - p^2)^{n-2},
    \end{align*}
    and so letting $X$ be the number of bad pairs, we compute using linearity of expectation that
    \begin{align*}
      \E{X} &= \E{\sum_{\{i,j\} \in \binom{[n]}{2}} \ind{B_{ij}}}\\
      &= \sum_{\{i,j\} \in \binom{[n]}{2}} \Prob{B_{ij}}\\
      &= \binom{n}{2}(1-p)(1 - p^2)^{n-2}
    \end{align*}
    which we easily see goes to zero for fixed $p \in (0,1)$ as $n \to \infty$.

    The result now follows by following the recipe for the first-moment method, applying Markov's inequality to see that we also have $\Prob{X > 0} \to 0$ as $n \to \infty$.
  \end{proof}
\end{proposition}

\section{Girth and chromatic number}

Already when we first introduced the chromatic number, we mentioned the obvious fact that a large clique forces a graph to have high chromatic number. One might be led by this to believe that being very sparse, without any cliques, would mean you have low chromatic number. This unfortunately turns out to be not at all true, in a pretty strong sense.

\begin{definition}
  The \emph{girth} of a graph $G$ is the length of the shortest cycle in the graph.
\end{definition}

So the notion of girth generalizes the notion of being triangle-free, which is just having girth greater than three. Of course any triangle-free graph also contains no larger cliques, so this is indeed a strong notion of having no cliques.

\begin{theorem}[Erd\H{o}s, 1959]
  For all positive integers $k$ there exists a graph $G$ of girth and chromatic number at least $k$.
\end{theorem}

The proof of this uses the probabilistic method, and proceeds by considering a random graph from a suitably chosen distribution, and showing that the probability that it has girth and chromatic number at least $k$ is greater than $0$. We postpone the proof of this until a later lecture, when we will have developed our probabilistic toolbox a bit more.


\section{Exercises}


%\bibliography{references}
%\bibliographystyle{plainnat}

\end{document}
